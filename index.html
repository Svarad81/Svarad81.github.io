<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8"/>
  <meta name="viewport" content="width=device-width,initial-scale=1"/>
  <title>Drowsiness Detector (fixed)</title>
  <style>
    body{font-family:system-ui,Segoe UI,Roboto,Arial;padding:12px;max-width:900px;margin:0 auto}
    .row{display:flex;gap:8px;align-items:center;margin:8px 0}
    video{width:100%;max-height:360px;border-radius:8px;transform:scaleX(-1);display:block}
    canvas{position:absolute;left:0;top:0}
    .box{background:#fff;padding:12px;border-radius:10px;box-shadow:0 1px 3px rgba(0,0,0,.08);margin-bottom:12px}
    pre{background:#111;color:#b8ffb8;padding:10px;border-radius:8px;height:180px;overflow:auto}
    #alert{display:none;background:#ffdddd;border:2px solid #ff5a5a;padding:10px;border-radius:8px;text-align:center;font-weight:700}
  </style>
</head>
<body>
  <h1>Drowsiness Detection ‚Äî fixed</h1>

  <div class="box">
    <div class="row">
      <input id="room" placeholder="Room ID (e.g. test1)" />
      <button id="roleDriver">Driver (Camera)</button>
      <button id="roleCar">Car (Listener)</button>
      <button id="start" disabled>Start</button>
      <button id="stop" disabled>Stop</button>
    </div>
    <small>Make sure you host on HTTPS (GitHub Pages) or run on localhost so camera works.)</small>
  </div>

  <div id="driverBox" class="box" style="display:none">
    <h3>Driver (Camera)</h3>
    <div style="position:relative">
      <video id="video" autoplay playsinline muted></video>
      <canvas id="overlay"></canvas>
    </div>
    <p id="status">EAR: -- | Consecutive: 0 | Frames analyzed: 0</p>
  </div>

  <div id="carBox" class="box" style="display:none">
    <h3>Car (Listener)</h3>
    <div id="alert">üö® Drowsiness Alert!</div>
    <button id="ack" style="display:none">Acknowledge</button>
  </div>

  <div class="box">
    <h3>Logs & Network</h3>
    <pre id="log"></pre>
  </div>

  <!-- TF + face-landmarks-detection (MediaPipe face mesh) -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.10.0/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/face-landmarks-detection@0.0.7/dist/face-landmarks-detection.min.js"></script>

  <script>
  // ===== CONFIG: put your JSONBin values here =====
  const JSONBIN_MASTER_KEY = "$2a$10$mdQ2p6Aczav/B7UASEbddOtXtV7ZukGzb1IoUPBX8Rg4kwcC7Z1Sq";
  const JSONBIN_BIN_ID    = "68cefa56d0ea881f408475ab";
  const JSONBIN_URL       = `https://api.jsonbin.io/v3/b/${JSONBIN_BIN_ID}`;
  // =================================================

  // PARAMETERS (tuneable)
  const EAR_THRESHOLD = 0.26;         // default threshold (try 0.26 - 0.28)
  const CONSEC_FRAMES = 15;           // you asked for 15 consecutive frames
  const POLL_MS = 3000;               // car polls every 3s
  const FRAME_DB_FREQ = 5;            // push frame to DB every N frames (reduce rate)

  // DOM
  const $room = document.getElementById('room');
  const $roleDriver = document.getElementById('roleDriver');
  const $roleCar = document.getElementById('roleCar');
  const $start = document.getElementById('start');
  const $stop = document.getElementById('stop');
  const $driverBox = document.getElementById('driverBox');
  const $carBox = document.getElementById('carBox');
  const $video = document.getElementById('video');
  const $overlay = document.getElementById('overlay');
  const $status = document.getElementById('status');
  const $log = document.getElementById('log');
  const $alert = document.getElementById('alert');
  const $ack = document.getElementById('ack');

  // state
  let role = null;
  let running = false;
  let model = null;
  let drowsyCount = 0;
  let analyzedFrames = 0;
  let frameCounter = 0;
  let lastAlertCount = 0;
  let pollIntervalId = null;
  let alertTimer = null;

  function log(msg){
    const t = new Date().toLocaleTimeString();
    $log.textContent = `[${t}] ${msg}\n` + $log.textContent;
    console.log(msg);
  }

  // role buttons
  $roleDriver.onclick = () => { role='driver'; $driverBox.style.display='block'; $carBox.style.display='none'; $start.disabled=false; log("Role: DRIVER"); };
  $roleCar.onclick = () =>    { role='car'; $carBox.style.display='block'; $driverBox.style.display='none'; $start.disabled=false; log("Role: CAR"); };

  $start.onclick = async () => {
    if(!role){ alert('Pick a role'); return; }
    if(!$room.value){ alert('Enter room ID'); return; }
    running = true; $start.disabled=true; $stop.disabled=false;
    if(role==='driver'){ await startDriver($room.value); }
    else startCar($room.value);
  };
  $stop.onclick = () => { stopAll(); };

  $ack.onclick = () => { stopAlert(); log('Alert acknowledged'); };

  // ---------- DRIVER (camera + detection) ----------
  async function startDriver(room){
    log('Requesting camera permission...');
    try{
      // try front camera; fallback to any camera
      let stream = null;
      try { stream = await navigator.mediaDevices.getUserMedia({video:{facingMode:'user'}}); }
      catch(e){ log('Front camera failed, trying default: '+e.message); stream = await navigator.mediaDevices.getUserMedia({video:true}); }

      $video.srcObject = stream;
      await $video.play();
      // set canvas size
      $overlay.width = $video.videoWidth;
      $overlay.height = $video.videoHeight;
      log(`Camera started ${$video.videoWidth}x${$video.videoHeight}`);

      // load model (face-landmarks-detection)
      log('Loading face-landmarks-detection model...');
      model = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);
      log('Model loaded.');

      // start loop
      detectLoop(room);
    }catch(err){
      log('Camera/model error: ' + err.message);
      alert('Camera or model failed: ' + err.message);
    }
  }

  // helper distances (landmarks come as [x,y,z] in pixels in this API)
  function dist(a,b){
    const dx = a[0]-b[0]; const dy = a[1]-b[1]; return Math.hypot(dx,dy);
  }
  function computeEAR(lm, idx){
    // idx is [p1,p2,p3,p4,p5,p6]
    const p1 = lm[idx[0]], p2 = lm[idx[1]], p3 = lm[idx[2]], p4 = lm[idx[3]], p5 = lm[idx[4]], p6 = lm[idx[5]];
    const A = dist(p2,p6);
    const B = dist(p3,p5);
    const C = dist(p1,p4);
    if(C === 0) return 0;
    return (A+B)/(2.0*C);
  }

  async function detectLoop(room){
    if(!running) return;
    if(!$video || $video.readyState < 2){
      requestAnimationFrame(()=>detectLoop(room));
      return;
    }

    // estimate faces
    let predictions = [];
    try{
      predictions = await model.estimateFaces({input: $video});
    }catch(e){
      log('estimateFaces error: '+e.message);
    }

    // draw basic overlay & debug
    const ctx = $overlay.getContext('2d');
    ctx.clearRect(0,0,$overlay.width,$overlay.height);

    frameCounter++;
    if(predictions && predictions.length>0){
      analyzedFrames++;
      const face = predictions[0];
      const lm = face.scaledMesh || face.mesh || []; // array of [x,y,z]

      // indices for EAR (MediaPipe mapping)
      const LEFT = [33,160,158,133,153,144];
      const RIGHT = [362,385,387,263,373,380];

      // guard: ensure indices exist
      if(lm.length > 400){
        const leftEAR = computeEAR(lm, LEFT);
        const rightEAR = computeEAR(lm, RIGHT);
        const ear = (leftEAR + rightEAR)/2;
        // update UI
        $status.textContent = `EAR: ${ear.toFixed(3)} | Consecutive: ${drowsyCount} | Frames analyzed: ${analyzedFrames}`;

        // draw small marker
        ctx.fillStyle='rgba(0,0,0,0.6)'; ctx.fillRect(6,6,140,28);
        ctx.fillStyle='white'; ctx.font='14px monospace';
        ctx.fillText(`EAR:${ear.toFixed(3)} f:${analyzedFrames}`, 10, 26);

        // persist frames occasionally to DB (reduce requests)
        if(frameCounter % FRAME_DB_FREQ === 0){
          saveFrameToDB(room, {timestamp:new Date().toISOString(), ear});
        }

        // detection logic
        if(ear < EAR_THRESHOLD){
          drowsyCount++;
          if(drowsyCount >= CONSEC_FRAMES){
            drowsyCount = 0;
            log('DROWSINESS: threshold crossed, sending alert');
            saveAlertToDB(room, {timestamp:new Date().toISOString(), type:'drowsiness', ear});
          }
        } else {
          drowsyCount = 0;
        }
      } else {
        // not enough landmarks yet
        $status.textContent = `EAR: -- | Consecutive: ${drowsyCount} | Frames analyzed: ${analyzedFrames}`;
      }
    } else {
      // no face
      $status.textContent = `EAR: -- | Consecutive: ${drowsyCount} | Frames analyzed: ${analyzedFrames}`;
    }

    // continue
    requestAnimationFrame(()=>detectLoop(room));
  }

  // ---------- JSONBin helpers ----------
  async function safeFetchGet(){
    const res = await fetch(JSONBIN_URL, { headers: { 'X-Master-Key': JSONBIN_MASTER_KEY } });
    if(!res.ok) throw new Error(`GET ${res.status} ${res.statusText}`);
    return await res.json();
  }

  async function safeFetchPut(recordObj){
    const res = await fetch(JSONBIN_URL, {
      method: 'PUT',
      headers: { 'Content-Type': 'application/json', 'X-Master-Key': JSONBIN_MASTER_KEY },
      body: JSON.stringify(recordObj)
    });
    if(!res.ok) throw new Error(`PUT ${res.status} ${res.statusText}`);
    return await res.json();
  }

  async function saveFrameToDB(room, frameObj){
    try{
      const bin = await safeFetchGet();
      const record = bin.record || {};
      record.sessions = record.sessions || {};
      record.sessions[room] = record.sessions[room] || { frames:[], alerts:[], sos:[] };
      record.sessions[room].frames.push(frameObj);
      await safeFetchPut(record);
      log(`Frame saved (ear=${frameObj.ear.toFixed(3)})`);
    }catch(e){
      log('Frame save failed: '+ e.message);
    }
  }

  async function saveAlertToDB(room, alertObj){
    try{
      const bin = await safeFetchGet();
      const record = bin.record || {};
      record.sessions = record.sessions || {};
      record.sessions[room] = record.sessions[room] || { frames:[], alerts:[], sos:[] };
      record.sessions[room].alerts.push(alertObj);
      await safeFetchPut(record);
      log('Alert saved to DB');
    }catch(e){
      log('Alert save failed: '+ e.message);
    }
  }

  // ---------- CAR role ----------
  function startCar(room){
    log('Car polling for alerts...');
    pollIntervalId = setInterval(()=>pollAlerts(room), POLL_MS);
  }

  async function pollAlerts(room){
    try{
      const bin = await safeFetchGet();
      const alerts = (bin.record && bin.record.sessions && bin.record.sessions[room] && bin.record.sessions[room].alerts) || [];
      if(alerts.length > lastAlertCount){
        lastAlertCount = alerts.length;
        showAlert();
      }
    }catch(e){ log('Car poll failed: '+e.message); }
  }

  function showAlert(){
    log('ALERT received by car');
    $alert.style.display='block';
    $ack.style.display='inline-block';
    // beep + vibrate
    try{ const ac = new (window.AudioContext||window.webkitAudioContext)(); const o = ac.createOscillator(); const g = ac.createGain(); o.type='sine'; o.frequency.value=880; o.connect(g); g.connect(ac.destination); g.gain.setValueAtTime(0.0001, ac.currentTime); g.gain.exponentialRampToValueAtTime(0.4, ac.currentTime+0.01); o.start(); setTimeout(()=>{ g.gain.exponentialRampToValueAtTime(0.0001, ac.currentTime+0.15); setTimeout(()=>o.stop(),200); }, 400);}catch(e){ log('Beep failed '+e.message); }
    if(navigator.vibrate) navigator.vibrate([200,100,200]);
    if(alertTimer) clearTimeout(alertTimer);
    alertTimer = setTimeout(()=>escalateSOS(), 15000);
  }

  function stopAlert(){
    $alert.style.display='none';
    $ack.style.display='none';
    if(alertTimer) clearTimeout(alertTimer);
  }

  async function escalateSOS(){
    const room = $room.value;
    log('Escalating to SOS (write to DB)');
    const sos = { timestamp:new Date().toISOString(), msg:'SOS (unacknowledged)' };
    try{
      const bin = await safeFetchGet();
      const record = bin.record || {};
      record.sessions = record.sessions || {};
      record.sessions[room] = record.sessions[room] || { frames:[], alerts:[], sos:[] };
      record.sessions[room].sos.push(sos);
      await safeFetchPut(record);
      alert('SOS logged in DB. Please contact emergency services manually.');
      stopAlert();
    }catch(e){ log('SOS save failed: '+ e.message); }
  }

  // ---------- stop all ----------
  function stopAll(){
    running = false;
    if($video.srcObject){ $video.srcObject.getTracks().forEach(t=>t.stop()); }
    if(pollIntervalId) clearInterval(pollIntervalId);
    stopAlert();
    $start.disabled=false; $stop.disabled=true;
    log('Stopped all.');
  }

  // Helpful startup check
  (function(){
    if(JSONBIN_MASTER_KEY.includes('YOUR_') || JSONBIN_BIN_ID.includes('YOUR_')){
      log('‚ö†Ô∏è Replace JSONBIN_MASTER_KEY and JSONBIN_BIN_ID at top of file with your values.');
    } else {
      log('JSONBin configured. Ready.');
    }
    // verify secure context (camera needs HTTPS/localhost)
    if(!location.protocol.startsWith('https') && location.hostname !== 'localhost'){
      log('‚ö†Ô∏è Warning: getUserMedia requires a secure context (HTTPS) or localhost. Camera may not work on file:// or plain http.');
    }
  })();
  </script>
</body>
</html>


